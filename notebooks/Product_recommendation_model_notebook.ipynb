{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## echoFace - Product Recommendation Model\n",
        "Multimodal User Authentication and Product Recommendation System\n",
        "\n",
        "This notebook implements the Product Recommendation component that predicts\n",
        "which product category a customer is likely to purchase based on their\n",
        "social media engagement and transaction history."
      ],
      "metadata": {
        "id": "Tw_3BNVWPRnX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kb64s68zBoR1",
        "outputId": "df5e4e3f-c42f-44a9-97a1-76320d58e7ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "scikit-learn version: 1.6.1\n",
            "\n",
            "================================================================================\n",
            "echoFace - Product Recommendation Model\n",
            "================================================================================\n",
            "Timestamp: 2025-11-12 13:31:58\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# 1. IMPORT LIBRARIES\n",
        "# ============================================================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "import os\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Machine Learning Libraries\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import (accuracy_score, f1_score, classification_report,\n",
        "                           confusion_matrix, log_loss)\n",
        "from xgboost import XGBClassifier\n",
        "import joblib\n",
        "\n",
        "# Check sklearn version\n",
        "import sklearn\n",
        "print(f\"scikit-learn version: {sklearn.__version__}\")\n",
        "\n",
        "# Set visualization style\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"echoFace - Product Recommendation Model\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "print(\"=\" * 80)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# 2. HELPER FUNCTIONS\n",
        "# ============================================================================\n",
        "\n",
        "def load_data(filepath):\n",
        "    \"\"\"Load dataset from CSV file.\"\"\"\n",
        "    df = pd.read_csv(filepath)\n",
        "    print(f\"✓ Loaded {filepath}\")\n",
        "    print(f\"  Shape: {df.shape}\")\n",
        "    return df\n",
        "\n",
        "def display_categorical(df):\n",
        "    \"\"\"Display distribution of categorical variables.\"\"\"\n",
        "    print(\"\\n--- Categorical Variable Distribution ---\")\n",
        "    print(\"\\nProduct Category Distribution:\")\n",
        "    display(df['product_category'].value_counts())\n",
        "    print(\"\\nSocial Media Platform Distribution:\")\n",
        "    display(df['social_media_platform'].value_counts())\n",
        "    print(\"\\nReview Sentiment Distribution:\")\n",
        "    display(df['review_sentiment'].value_counts())\n",
        "\n",
        "def data_preprocessing(df, le):\n",
        "    \"\"\"\n",
        "    Preprocess the merged dataset:\n",
        "    - Extract date features\n",
        "    - Drop irrelevant columns\n",
        "    - Encode categorical variables\n",
        "    \"\"\"\n",
        "    print(\"\\n--- Data Preprocessing ---\")\n",
        "\n",
        "    # Create temporal features from purchase_date\n",
        "    df['purchase_date'] = pd.to_datetime(df['purchase_date'])\n",
        "    df['year'] = df['purchase_date'].dt.year\n",
        "    df['month'] = df['purchase_date'].dt.month\n",
        "    df['day'] = df['purchase_date'].dt.day\n",
        "    df['weekday'] = df['purchase_date'].dt.day_of_week\n",
        "    df['isweekend'] = (df['weekday'] >= 5).astype(int)\n",
        "\n",
        "    # Drop columns not needed for prediction\n",
        "    df.drop(columns='purchase_date', inplace=True)\n",
        "    df = df.drop(['customer_id', 'transaction_id', 'year'], axis=1)\n",
        "\n",
        "    # Get numerical columns (before encoding)\n",
        "    numeric_cols = df.select_dtypes(include=[np.number]).columns.drop('isweekend')\n",
        "\n",
        "    # Label encode target variable (product_category)\n",
        "    df['product_category'] = le.fit_transform(df['product_category'])\n",
        "\n",
        "    # Ordinal encoding for review sentiment\n",
        "    sentiment_mapping = {'Negative': 0, 'Neutral': 1, 'Positive': 2}\n",
        "    df['review_sentiment'] = df['review_sentiment'].map(sentiment_mapping)\n",
        "\n",
        "    # One-hot encode social media platform\n",
        "    df = pd.get_dummies(df, columns=['social_media_platform'], dtype=int)\n",
        "\n",
        "    # Print label mapping\n",
        "    print(\"\\n✓ Product Category Encoding:\")\n",
        "    for idx, category in enumerate(le.classes_):\n",
        "        print(f\"  {category} = {idx}\")\n",
        "\n",
        "    return df, numeric_cols\n",
        "\n",
        "def prep_data(df):\n",
        "    \"\"\"Prepare features and target, split into train/test sets.\"\"\"\n",
        "    X = df.drop('product_category', axis=1)\n",
        "    y = df['product_category']\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, stratify=y, random_state=42\n",
        "    )\n",
        "\n",
        "    print(f'\\n--- Train-Test Split ---')\n",
        "    print(f'X_train shape: {X_train.shape}')\n",
        "    print(f'X_test shape: {X_test.shape}')\n",
        "    print(f'y_train shape: {y_train.shape}')\n",
        "    print(f'y_test shape: {y_test.shape}')\n",
        "\n",
        "    return X, y, X_train, X_test, y_train, y_test\n",
        "\n",
        "def save_model_artifacts(model, scaler, le, final_columns, numeric_cols, output_dir='../models/product/'):\n",
        "    \"\"\"Save all model artifacts needed for prediction.\"\"\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    joblib.dump(model, os.path.join(output_dir, 'product_recommendation_model.pkl'))\n",
        "    joblib.dump(scaler, os.path.join(output_dir, 'product_model_scaler.pkl'))\n",
        "    joblib.dump(le, os.path.join(output_dir, 'product_model_encoder.pkl'))\n",
        "    joblib.dump(final_columns, os.path.join(output_dir, 'product_model_columns.pkl'))\n",
        "    joblib.dump(numeric_cols, os.path.join(output_dir, 'product_model_numeric_cols.pkl'))\n",
        "\n",
        "    print(f\"\\n✓ All model artifacts saved to '{output_dir}'\")\n",
        "    print(\"  - product_recommendation_model.pkl\")\n",
        "    print(\"  - product_model_scaler.pkl\")\n",
        "    print(\"  - product_model_encoder.pkl\")\n",
        "    print(\"  - product_model_columns.pkl\")\n",
        "    print(\"  - product_model_numeric_cols.pkl\")"
      ],
      "metadata": {
        "id": "wKP0jzWKRIrw"
      },
      "execution_count": 2,
      "outputs": []
    }
  ]
}